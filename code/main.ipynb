{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input txt\n",
    "def readTxt():\n",
    "    data = []\n",
    "    with open(\"../data/R15.txt\",\"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.strip(\"\\n\")\n",
    "            line = line.split()\n",
    "            data.append([float(i) for i in line])   \n",
    "    return data\n",
    "df = readTxt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input csv\n",
    "import pandas as pd\n",
    "df = pd.read_csv('../data/spiral_312p_2d_3c.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df = np.array(df, dtype = np.float32)\n",
    "df_square = np.sum(df ** 2, axis=1, keepdims=True)\n",
    "dist_square = df_square - 2 * df.dot(df.T) + df_square.T\n",
    "dist_square = np.where(dist_square < 0, 0, dist_square) # to avoid negative float like -10^(-5)\n",
    "dist = np.sqrt(dist_square)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# super-parameter d_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_flatten = dist.flatten()\n",
    "dist_flatten = np.sort(dist_flatten)\n",
    "N = len(df)\n",
    "percentage = 0.02 # super-parameter\n",
    "d_c = dist_flatten[round(N**2*percentage)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune:\n",
    "* 论文中推荐1%-2%，我发现2%可用于D31、R15，看来2%的确是一个还不错的值。\n",
    "* Aggregation数据集需要调调参，我调了几次，发现4%比较合适。（这个算法的确帅气、优美、简洁、普适，我调了几下就调出来了）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_d_c(d_c, N):\n",
    "#     n = 0\n",
    "#     for i in range(N):\n",
    "#         x = dist[i,:]\n",
    "#         n = n + sum( x - d_c < 0)\n",
    "#     n = n / N\n",
    "#     if n > 0.01 * N and n < 0.02 * N:\n",
    "#         print(\"OK\")\n",
    "#     else:\n",
    "#         print(\"not OK\")\n",
    "#     return n\n",
    "# n = test_d_c(d_c, N)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate $\\rho$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step kernal\n",
    "# rou = np.zeros([N,2])\n",
    "# rou[:,0] = np.arange(0, N)\n",
    "# for i in range(N):\n",
    "#     x = dist[i,:]\n",
    "#     rou[i,1] = sum( x - d_c < 0)\n",
    "# temp = np.lexsort(-rou.T)\n",
    "# rou = rou[temp,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gauss kernal\n",
    "import math\n",
    "rho_Gauss = np.zeros([N,2])\n",
    "rho_Gauss[:,0] = np.arange(0, N)\n",
    "for i in range(N-1):\n",
    "    for j in range(i+1,N):\n",
    "        rho_Gauss[i,1] = rho_Gauss[i,1] + math.exp(-(dist[i,j]/d_c)**2)\n",
    "        rho_Gauss[j,1] = rho_Gauss[j,1] + math.exp(-(dist[i,j]/d_c)**2)\n",
    "rho_Gauss = rho_Gauss[np.lexsort(-rho_Gauss.T),:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate $\\delta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = np.zeros([N,2])\n",
    "delta[:,0] = rho_Gauss[:,0]\n",
    "for i in range(1,N):\n",
    "    d = np.zeros(i)\n",
    "    for j in range(i):        \n",
    "        d[j] = dist[int(rho_Gauss[i,0]),int(rho_Gauss[j,0])]\n",
    "    delta[i,1] = min(d)\n",
    "delta[0,1] = max(delta[:,1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot delta~rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = rho_Gauss[:,1]\n",
    "y = delta[:,1]\n",
    "fig = plt.figure() \n",
    "ax1 = fig.add_subplot(111)\n",
    "plt.xlabel('rou') \n",
    "plt.ylabel('delta') \n",
    "ax1.scatter(x, y, marker='o') \n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# choose the cluster centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method1: use rho*delta\n",
    "point = np.zeros([N,4])\n",
    "point[:,0:2] = rho_Gauss\n",
    "point[:,2] = delta[:,1]\n",
    "point[:,3] = rho_Gauss[:,1] * delta[:,1]\n",
    "temp = np.lexsort(-point.T)\n",
    "point = point[temp,:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot $\\rho \\cdot \\delta$ ~ number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x_2 = np.arange(0, N) # 0, 1, 2 ... 599\n",
    "y_2 = point[:,3]\n",
    "fig = plt.figure() \n",
    "ax1 = fig.add_subplot(111)\n",
    "plt.xlabel('point number') \n",
    "plt.ylabel('rou*delta') \n",
    "ax1.scatter(x_2, y_2, marker='o') \n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the cluster centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = np.quantile(point[:,3], 0.5) # use quantile to avoid another super-parameter\n",
    "for i in range(1, N):\n",
    "    z = np.logical_and(point[:,3] > step*i, point[:,3] <= step*(i+1))\n",
    "    if sum(z) == 0:\n",
    "        break\n",
    "number_of_cluster = sum(point[:,3] > step*i)\n",
    "id_of_cluster_center = point[0:number_of_cluster,0]\n",
    "id_of_cluster_center = id_of_cluster_center.astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "other paussible method to choose the cluster centers\n",
    "* method2: use 2 percentage as threshold\n",
    "* method3: use cluster method or SVM in delta~rho or rou*delta~t\n",
    "* method4: let the user draw a rectangular (the original paper use this straightforward but subjective method)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot cluster graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the cluster center in red and others in blue\n",
    "x = df[:,0]\n",
    "y = df[:,1]\n",
    "fig = plt.figure() \n",
    "ax1 = fig.add_subplot(111)\n",
    "plt.xlabel('X') \n",
    "plt.ylabel('Y') \n",
    "ax1.set_title('Scatter Plot') \n",
    "ax1.scatter(x, y, marker='o') \n",
    "x_center = df[id_of_cluster_center,0]\n",
    "y_center = df[id_of_cluster_center,1]\n",
    "ax1.scatter(x_center, y_center, c='r', marker='o')\n",
    "plt.show() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "each remaining point is assigned to the same cluster as its nearest neighbor of higher density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "column of point:\n",
    "* c0 is id\n",
    "* c1 is rho\n",
    "* c2 is delta\n",
    "* c3 is rho*delta\n",
    "* c4 is cluster label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new column for cluster label\n",
    "point = np.append(point, np.zeros([N,1]), axis=1)\n",
    "\n",
    "# put the cluster center into each cluster\n",
    "for i in range(number_of_cluster):\n",
    "    point[i,4] = i + 1\n",
    "\n",
    "# descend points by id\n",
    "point_descend_by_id = point[np.argsort(point[:, 0])]\n",
    "\n",
    "# flag for dist\n",
    "is_dist = dist <= d_c * 5 # I use 5 to make sure that I can find a neighbor with higher density. # 5 is kind of super-parameter, can be 100 too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_the_nearest_neighbor_with_higher_density(i):\n",
    "\n",
    "    global point_descend_by_id\n",
    "\n",
    "    # if this point already has id\n",
    "    if point_descend_by_id[i,4] != 0:\n",
    "        return\n",
    "    \n",
    "    flag_neighbor = is_dist[i,:]\n",
    "    dist_neighbor = dist[i,:][flag_neighbor]\n",
    "    neighbor = point_descend_by_id[flag_neighbor]\n",
    "    neighbor = np.append(neighbor, dist_neighbor[:,np.newaxis], axis=1)\n",
    "    neighbor = neighbor[neighbor[:,1] > point_descend_by_id[i,1] + 10**(-4)] # 10**(-4) is used to avoid include itself\n",
    "    neighbor = neighbor[np.argsort(neighbor[:, 5])]\n",
    "    if neighbor[0,4] != 0:\n",
    "        point_descend_by_id[i,4] = neighbor[0,4]\n",
    "    else:\n",
    "        find_the_nearest_neighbor_with_higher_density(int(neighbor[0,0])) # recursion\n",
    "        point_descend_by_id[i,4] = point_descend_by_id[int(neighbor[0,0]),4]\n",
    "for i in range(N):\n",
    "    find_the_nearest_neighbor_with_higher_density(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure() \n",
    "ax1 = fig.add_subplot(111)\n",
    "plt.xlabel('X') \n",
    "plt.ylabel('Y') \n",
    "ax1.set_title('Scatter Plot')\n",
    "ax1.scatter(df[:,0], df[:,1], c = point_descend_by_id[:,4], cmap = \"tab20\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Davies-Bouldin Index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "metrics.davies_bouldin_score(df, point_descend_by_id[:,4])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Aggregation: 0.5036\n",
    "* R15: 0.3148\n",
    "* D31: 0.5519"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conclusion\n",
    "* this algorithm\n",
    "  * 该算法帅气优雅简洁（自不必说）、普适（可以用于球形和非球形数据集），是我们物理学家会喜欢的算法。\n",
    "  * 该算法结合了K-means和DBSCAN的优点\n",
    "* Further improvement\n",
    "  * 光晕点\n",
    "    * 原论文中给出了光晕点的定义，这个定义自然地给出了寻找方法\n",
    "    * 所有的光晕点为新的一类，用一种新的颜色表示\n",
    "  * 离群点\n",
    "    * 原论文中把$\\rho$小$\\delta$大的点定义为离群点\n",
    "    * 我们也可以把在$5d_c$中都没有更大密度邻居的点定义为离群点\n",
    "    * 所有的离群点也可以被划分为新的一类，用一种新的颜色表示"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf245e2d5e4a2aef58e3292d21e566cf0ee03e2e9151002f5de995cbc6bcfd67"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
