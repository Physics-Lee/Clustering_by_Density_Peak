{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def my_sort(arr, col_index, order):\n",
    "    \"\"\"\n",
    "    Sorts a NumPy array by a specific column in ascending or descending order.\n",
    "\n",
    "    Parameters:\n",
    "        arr (numpy.ndarray): The array to sort.\n",
    "        col_index (int): The index of the column to sort by.\n",
    "        order (str): 'ascending' or 'descending'\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The sorted array.\n",
    "    \"\"\"\n",
    "\n",
    "    if order == 'ascending':\n",
    "        # Get the indices that would sort the specified column in ascending order\n",
    "        sorted_indices = np.argsort(arr[:, col_index])\n",
    "        \n",
    "        # Sort the entire array by these indices\n",
    "        sorted_arr = arr[sorted_indices]\n",
    "\n",
    "    if order == 'descending':\n",
    "        # Get the indices that would sort the specified column in descending order\n",
    "        sorted_indices = np.argsort(-arr[:, col_index])\n",
    "        \n",
    "        # Sort the entire array by these indices\n",
    "        sorted_arr = arr[sorted_indices]\n",
    "    \n",
    "    return sorted_arr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input txt\n",
    "def readTxt():\n",
    "    data = []\n",
    "    with open(\"../data/R15.txt\",\"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.strip(\"\\n\")\n",
    "            line = line.split()\n",
    "            data.append([float(i) for i in line])   \n",
    "    return data\n",
    "df = readTxt()\n",
    "df = np.array(df, dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input csv\n",
    "# import pandas as pd\n",
    "# df = pd.read_csv('../data/spiral_312p_2d_3c.csv', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calulate pair-wise distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# df_square = np.sum(df ** 2, axis=1, keepdims=True)\n",
    "# dist_square = df_square - 2 * df.dot(df.T) + df_square.T\n",
    "# dist_square = np.where(dist_square < 0, 0, dist_square) # to avoid negative float like -10^(-5)\n",
    "# dist = np.sqrt(dist_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "# Calculate the pairwise Euclidean distance matrix using scipy\n",
    "dist = distance.cdist(df, df, 'euclidean')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tune super-parameter d_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_flatten = dist.flatten()\n",
    "dist_flatten = np.sort(dist_flatten)\n",
    "n_points = len(df)\n",
    "percentage = 0.02 # super-parameter\n",
    "d_c = dist_flatten[round(n_points**2*percentage)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note\n",
    "* 论文中推荐1%-2%，我发现2%可用于D31、R15，看来2%的确是一个还不错的值。\n",
    "* Aggregation数据集需要调调参，我调了几次，发现4%比较合适。（这个算法的确帅气、优美、简洁、普适，我调了几下就调出来了）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_d_c(d_c, N):\n",
    "#     n = 0\n",
    "#     for i in range(N):\n",
    "#         x = dist[i,:]\n",
    "#         n = n + sum( x - d_c < 0)\n",
    "#     n = n / N\n",
    "#     if n > 0.01 * N and n < 0.02 * N:\n",
    "#         print(\"OK\")\n",
    "#     else:\n",
    "#         print(\"not OK\")\n",
    "#     return n\n",
    "# n = test_d_c(d_c, N)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate $\\rho$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # step kernal\n",
    "# rho_Heaviside = np.zeros([N,2])\n",
    "# rho_Heaviside[:,0] = np.arange(0, N)\n",
    "# for i in range(N):\n",
    "#     rho_Heaviside[i,1] = sum(dist[i,:] - d_c < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gauss kernal\n",
    "import math\n",
    "rho_Gauss = np.zeros([n_points,2])\n",
    "rho_Gauss[:,0] = np.arange(0, n_points)\n",
    "for i in range(n_points-1):\n",
    "    for j in range(i+1,n_points):\n",
    "        rho_Gauss[i,1] = rho_Gauss[i,1] + math.exp(-(dist[i,j]/d_c)**2)\n",
    "        rho_Gauss[j,1] = rho_Gauss[j,1] + math.exp(-(dist[i,j]/d_c)**2)\n",
    "\n",
    "# sort by descending order\n",
    "rho_Gauss = my_sort(rho_Gauss, 1, 'descending')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate $\\delta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Process all points except the one with highest rho\n",
    "#\n",
    "\n",
    "# init\n",
    "delta = np.zeros([n_points,2])\n",
    "delta[:,0] = rho_Gauss[:,0]\n",
    "d_max = np.max(dist)\n",
    "nearest_neighbor_of_higher_density = np.zeros([n_points,2])\n",
    "nearest_neighbor_of_higher_density[:,0] = rho_Gauss[:,0]\n",
    "\n",
    "for i in range(1, n_points):\n",
    "\n",
    "    # index for points\n",
    "    idx_i = int(rho_Gauss[i, 0])\n",
    "    idx_js = rho_Gauss[:i, 0].astype(int)  # Convert to int for indexing\n",
    "\n",
    "    # calculate the distances between point i and all points with higher density\n",
    "    d_now = dist[idx_i, idx_js]\n",
    "\n",
    "    # calculate delta\n",
    "    delta[i, 1] = np.min(d_now)\n",
    "\n",
    "    # get the nearest neighbor of higher density\n",
    "    nearest_neighbor_of_higher_density[i, 1] = int(rho_Gauss[np.argmin(d_now), 0])\n",
    "\n",
    "# For the point with highest rho, let delta be the maximum among all deltas\n",
    "delta[0, 1] = np.max(delta[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_Gauss[np.argmin(d_now), 0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot delta~rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(rho_Gauss[:, 1], delta[:, 1], marker='o')\n",
    "plt.xlabel('rou')\n",
    "plt.ylabel('delta')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# choose the cluster centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_descended_by_gamma = np.zeros([n_points,4])\n",
    "points_descended_by_gamma[:,0:2] = rho_Gauss\n",
    "points_descended_by_gamma[:,2] = delta[:,1]\n",
    "points_descended_by_gamma[:,3] = rho_Gauss[:,1] * delta[:,1]\n",
    "points_descended_by_gamma = my_sort(points_descended_by_gamma,3,'descending')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "column of points:\n",
    "* c0 is id\n",
    "* c1 is rho\n",
    "* c2 is delta\n",
    "* c3 is rho*delta\n",
    "* c4 is cluster label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot $\\rho \\cdot \\delta$ ~ number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "rank = np.arange(0, n_points)\n",
    "plt.scatter(rank, points_descended_by_gamma[:,3], marker='o')\n",
    "plt.xlabel('point number')\n",
    "plt.ylabel('rou*delta')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the cluster centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = np.quantile(points_descended_by_gamma[:,3], 0.5) # use quantile to avoid another super-parameter\n",
    "for i in range(1, n_points):\n",
    "    z = np.logical_and(points_descended_by_gamma[:,3] > step*i, points_descended_by_gamma[:,3] <= step*(i+1))\n",
    "    if sum(z) == 0:\n",
    "        break\n",
    "n_cluster = sum(points_descended_by_gamma[:,3] > step*i)\n",
    "id_of_cluster_center = points_descended_by_gamma[0:n_cluster,0]\n",
    "id_of_cluster_center = id_of_cluster_center.astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "other paussible method to choose the cluster centers\n",
    "* method2: use 2 percentage as threshold\n",
    "* method3: use cluster method or SVM in delta~rho or rou*delta~t\n",
    "* method4: let the user draw a rectangular (the original paper use this straightforward but subjective method)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot cluster centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# plot the cluster center in red and others in blue\n",
    "#\n",
    "\n",
    "# Scatter plot for x and y\n",
    "plt.scatter(df[:, 0], df[:, 1], marker='o')\n",
    "\n",
    "# Scatter plot for cluster center\n",
    "plt.scatter(df[id_of_cluster_center, 0], df[id_of_cluster_center, 1], c='r', marker='o')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Scatter Plot with Cluster Centers')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# allocate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new column for cluster label\n",
    "points_descended_by_gamma = np.append(points_descended_by_gamma, np.zeros([n_points,1]), axis=1)\n",
    "\n",
    "# put the cluster center into each cluster\n",
    "for i in range(n_cluster):\n",
    "    points_descended_by_gamma[i,4] = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descend points by id\n",
    "points_descended_by_id = my_sort(points_descended_by_gamma,0,'descending')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descend points by rho\n",
    "points_descended_by_rho = my_sort(points_descended_by_gamma,1,'descending')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## method 1\n",
    "each remaining point is assigned to the same cluster as its nearest neighbor within 5 $d_c$ of higher density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # flag for dist\n",
    "# is_neigh = dist <= d_c * 5 # I use 5 to make sure that I can find a neighbor with higher density. # 5 is kind of super-parameter, can be 100 too.\n",
    "\n",
    "# def find_the_nearest_neighbor_with_higher_density(i):\n",
    "\n",
    "#     # if this point already has label\n",
    "#     if points_descended_by_id[i,4] != 0:\n",
    "#         return\n",
    "    \n",
    "#     # get all neighbors for point i\n",
    "#     flag_neighbor = is_neigh[i,:]\n",
    "#     neighbor = points_descended_by_id[flag_neighbor]\n",
    "\n",
    "#     # get dists between point i and its neighbors\n",
    "#     dist_neighbor = dist[i,:][flag_neighbor]\n",
    "\n",
    "#     # find the neighbors with higher density\n",
    "#     neighbor = np.append(neighbor, dist_neighbor[:,np.newaxis], axis=1)\n",
    "#     neighbor = neighbor[neighbor[:,1] > points_descended_by_id[i,1] + 10**(-4)] # 10**(-4) is used to avoid include itself\n",
    "    \n",
    "#     # sort by distance (from closest to farthest)\n",
    "#     neighbor = neighbor[np.argsort(neighbor[:, 5])]\n",
    "\n",
    "#     # if the highest density neighbor already has label\n",
    "#     if neighbor[0,4] != 0:\n",
    "#         points_descended_by_id[i,4] = neighbor[0,4]\n",
    "    \n",
    "#     # if the highest density neighbor has no label\n",
    "#     else:\n",
    "#         find_the_nearest_neighbor_with_higher_density(int(neighbor[0,0])) # recursion\n",
    "#         points_descended_by_id[i,4] = points_descended_by_id[int(neighbor[0,0]),4]\n",
    "\n",
    "# # loop to find the cluster for each point\n",
    "# for i in range(N):\n",
    "#     find_the_nearest_neighbor_with_higher_density(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## method 2\n",
    "each remaining point is assigned to the same cluster as its nearest neighbor within $+\\infty$ of higher density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_points):\n",
    "    if points_descended_by_rho[i,4] == 0:\n",
    "        idx = int(nearest_neighbor_of_higher_density[i,1])\n",
    "        position = np.where(points_descended_by_rho[:,0] == idx)[0]\n",
    "        points_descended_by_rho[i,4] = int(points_descended_by_rho[position,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_color_map(cluster_label, max_colors=100, skip=5):\n",
    "\n",
    "    unique_labels = np.unique(cluster_label)\n",
    "    \n",
    "    # Generate distinct colors\n",
    "    available_colors = plt.cm.gnuplot(np.linspace(0, 1, max_colors))\n",
    "    \n",
    "    # Create a dynamic color map: This dictionary assigns a fixed color to each unique value in 'unique_labels'\n",
    "    color_map = {}\n",
    "    for i, label in enumerate(unique_labels):\n",
    "        color_map[label] = available_colors[(i * skip) % max_colors]\n",
    "        \n",
    "    return color_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_ascended_by_id = my_sort(points_descended_by_rho,0,'ascending')\n",
    "cluster_label = points_ascended_by_id[:,4].astype(int)\n",
    "\n",
    "# color_map = generate_color_map(cluster_label)\n",
    "# colors = [color_map[label] for label in cluster_label]\n",
    "\n",
    "plt.scatter(df[:, 0], df[:, 1], c = cluster_label, cmap=\"tab20\")\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Scatter Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Border Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_label_bord = cluster_label.copy()\n",
    "    \n",
    "# Initialize bord_rho array\n",
    "bord_rho = np.zeros(n_cluster)\n",
    "\n",
    "# Loop to update bord_rho\n",
    "for i in range(n_points - 1):\n",
    "    for j in range(i + 1, n_points):\n",
    "        if cluster_label[i] != cluster_label[j] and dist[i, j] <= d_c:\n",
    "\n",
    "            # add label for border region\n",
    "            cluster_label_bord[i] = 0\n",
    "            cluster_label_bord[j] = 0\n",
    "            \n",
    "            # Update bord_rho for cluster_label[i]\n",
    "            if rho_Gauss[i,1] > bord_rho[cluster_label[i] - 1]:\n",
    "                bord_rho[cluster_label[i] - 1] = rho_Gauss[i,1]\n",
    "            \n",
    "            # Update bord_rho for cluster_label[j]\n",
    "            if rho_Gauss[j,1] > bord_rho[cluster_label[j] - 1]:\n",
    "                bord_rho[cluster_label[j] - 1] = rho_Gauss[j,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_Gauss[248,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "plt.scatter(df[:, 0], df[:, 1], c = cluster_label, cmap=\"tab20\")\n",
    "\n",
    "# plot bolder region\n",
    "idx_border = np.where(cluster_label_bord == 0)[0]\n",
    "plt.scatter(df[idx_border, 0], df[idx_border, 1], c='black', marker='o')\n",
    "\n",
    "# label and title\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Scatter Plot with Border Region')\n",
    "\n",
    "# \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Halo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "halo = cluster_label.copy()\n",
    "for i in range(n_points):\n",
    "    if rho_Gauss[i,1] < bord_rho[cluster_label[i] - 1]:\n",
    "        halo[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "plt.scatter(df[:, 0], df[:, 1], c = cluster_label, cmap=\"tab20\")\n",
    "\n",
    "# plot halo\n",
    "idx_halo = np.where(halo == 0)[0]\n",
    "plt.scatter(df[idx_halo, 0], df[idx_halo, 1], c='black', marker='o')\n",
    "\n",
    "# label and title\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Scatter Plot with Halo')\n",
    "\n",
    "# \n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Davies-Bouldin Index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "metrics.davies_bouldin_score(df, cluster_label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Aggregation: 0.5036\n",
    "* R15: 0.3148\n",
    "* D31: 0.5519"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conclusion\n",
    "* this algorithm\n",
    "  * 该算法帅气优雅简洁（自不必说）、普适（可以用于球形和非球形数据集），是我们物理学家会喜欢的算法。\n",
    "  * 该算法结合了K-means和DBSCAN的优点\n",
    "* Further improvement\n",
    "  * 光晕点\n",
    "    * 原论文中给出了光晕点的定义，这个定义自然地给出了寻找方法\n",
    "    * 所有的光晕点为新的一类，用一种新的颜色表示\n",
    "  * 离群点\n",
    "    * 原论文中把$\\rho$小$\\delta$大的点定义为离群点\n",
    "    * 我们也可以把在$5d_c$中都没有更大密度邻居的点定义为离群点\n",
    "    * 所有的离群点也可以被划分为新的一类，用一种新的颜色表示"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
